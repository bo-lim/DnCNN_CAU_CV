# -*- coding: utf-8 -*-
"""model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1emjL-RoYJpodNGZlDrLVXKgY3fQStf6T
"""

# importing
import torch
import torch.nn as nn

# class
class DnCNN(nn.Module):
    def __init__(self, num_layers=17, num_channels=64, image_channels=1, use_bnorm=True, kernel_size=3):
        '''
        self
        num_of_channels
        num_of_layers

        make sequential layers
        '''
        super(DnCNN, self).__init__()
        kernel_size = 3
        padding = 1
        eps = 0.0001
        momentum = 0.95
        # hyper parameter
        # num_of_channels(num_channels) = 64
        # self.num_of_layers(num_layers) = 17
        # self.is_used_bn(use_bnorm) = True
        layers = [nn.Sequential(nn.Conv2d(in_channels=image_channels, out_channels=num_channels, kernel_size=kernel_size, stride=1, padding=padding),
                                nn.ReLU(inplace=True))]
        for i in range(num_layers - 2):
            layers.append(nn.Sequential(nn.Conv2d(in_channels=num_channels, out_channels=num_channels, kernel_size=kernel_size, padding=padding),
                                        nn.BatchNorm2d(num_channels, eps=eps, momentum=momentum),
                                        nn.ReLU(inplace=True)))
        layers.append(nn.Conv2d(in_channels=num_channels, out_channels=image_channels, kernel_size=kernel_size, padding=padding))
        self.dncnn = nn.Sequential(*layers)

        self._initialize_weights()

        # self.input_conv = nn.Conv2d(1, num_of_channels, kernel_size = kernel_size, padding = 'same')
        # self.conv = nn.Conv2d(num_of_channels, num_of_channels, kernel_size = kernel_size, padding = 'same')
        # self.relu = nn.ReLU()
        # self.bn = nn.BatchNorm2d(num_of_channels, eps = eps, momentum=momentum)
        # self.output_conv = nn.Conv2d(num_of_channels, 1, kernel_size = kernel_size, padding = 'same')
        # initialize_weights
    
    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.kaiming_normal_(m.weight)
            elif isinstance(m, nn.BatchNorm2d):
                nn.init.ones_(m.weight)
                nn.init.zeros_(m.bias)
    
    def forward(self, inputs):
        '''
        self
        x

        return: x-y
        '''
        # MODEL Architecture
        # y = self.input_conv(x)
        # y = self.relu(y)
        # for d in range(self.num_of_layers-2):
        #         y = self.conv(y)
        #         if self.is_used_bn:
        #             y = self.bn(y)
        #         y = self.relu(y)
        # y = self.output_conv(y)
        # return x - y
        y = inputs
        residual = self.dncnn(y)
        return y - residual